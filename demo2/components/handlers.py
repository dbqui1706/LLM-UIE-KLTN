import json
from typing import Dict, Any, Tuple
from .presets import GenerationPresets
from ..utils.sample import get_sample_texts

class EventHandlers:
    """
    Event handlers cho Gradio components
    Chia th√†nh c√°c handler ri√™ng bi·ªát cho t·ª´ng tab v√† ch·ª©c nƒÉng
    """
    
    def __init__(self, context):
        self.context = context
        self.sample_texts = get_sample_texts()
    
    # ============================================================================
    # TEXT EXTRACTION HANDLERS
    # ============================================================================
    
    def load_sample_text(self, sample_name: str) -> str:
        """
        Load sample text khi user ch·ªçn t·ª´ dropdown
        
        Args:
            sample_name: T√™n c·ªßa sample text ƒë∆∞·ª£c ch·ªçn
            
        Returns:
            Text content c·ªßa sample ƒë∆∞·ª£c ch·ªçn
        """
        if sample_name and sample_name in self.sample_texts:
            return self.sample_texts[sample_name]
        return ""
    
    def process_text_extraction(self, text: str, task: str, entity_types: str, 
                               relation_types: str, event_types: str, argument_types: str, 
                               mode: str, *generation_params) -> Tuple[str, str]:
        """
        X·ª≠ l√Ω text extraction v·ªõi c√°c generation parameters
        
        Args:
            text: Input text c·∫ßn extract
            task: Lo·∫°i task (NER, RE, EE, ALL)
            entity_types, relation_types, event_types, argument_types: Custom schema
            mode: Extraction mode (flexible, strict, open)
            *generation_params: C√°c tham s·ªë generation t·ª´ UI controls
            
        Returns:
            Tuple[summary_text, detailed_json]
        """
        try:
            # G·ªçi model extraction v·ªõi parameters
            result = self.context.extract_information(
                text=text,
                task=task,
                entity_types=entity_types,
                relation_types=relation_types,
                event_types=event_types,
                argument_types=argument_types,
                mode=mode,
                *generation_params  # Unpack generation parameters
            )
            
            # X·ª≠ l√Ω l·ªói
            if "error" in result:
                return result["error"], ""
            
            # Format output
            summary = self._create_extraction_summary(result)
            detailed_json = json.dumps(result, indent=2, ensure_ascii=False)
            
            return summary, detailed_json
            
        except Exception as e:
            error_msg = f"‚ùå Extraction failed: {str(e)}"
            return error_msg, ""
    
    def _create_extraction_summary(self, result: Dict[str, Any]) -> str:
        """
        T·∫°o summary text cho extraction results
        
        Args:
            result: K·∫øt qu·∫£ extraction t·ª´ model
            
        Returns:
            Summary string ƒë·ªÉ hi·ªÉn th·ªã
        """
        summary_parts = []
        
        # Count results
        if "entities" in result:
            summary_parts.append(f"üè∑Ô∏è Entities: {len(result['entities'])}")
        if "relations" in result:
            summary_parts.append(f"üîó Relations: {len(result['relations'])}")
        if "events" in result:
            summary_parts.append(f"üìÖ Events: {len(result['events'])}")
        
        # Add generation info n·∫øu c√≥
        if "generation_info" in result:
            gen_info = result["generation_info"]["parameters_used"]
            summary_parts.append(f"üéõÔ∏è Temp: {gen_info['temperature']}")
            summary_parts.append(f"üéØ Tokens: {gen_info['max_new_tokens']}")
        
        return " | ".join(summary_parts) if summary_parts else "No results found"
    
    # ============================================================================
    # DOCUMENT PROCESSING HANDLERS  
    # ============================================================================
    
    def process_document_upload(self, file, processing_mode: str, use_gpu: bool, 
                               enable_ocr: bool, enable_table_structure: bool,
                               enable_cleaning: bool, aggressive_clean: bool,
                               enable_chunking: bool, chunking_strategy: str,
                               chunk_size: int, chunk_overlap: int, task_type: str,
                               *generation_params) -> Tuple[str, str, str]:
        """
        X·ª≠ l√Ω document upload v√† processing
        
        Args:
            file: Uploaded file object
            processing_mode, use_gpu, etc.: Processing options
            *generation_params: Generation parameters
            
        Returns:
            Tuple[summary_markdown, detailed_json, chunks_preview]
        """
        # Ki·ªÉm tra file upload
        if file is None:
            return "‚ùå Please upload a file first", "", ""
        
        try:
            # G·ªçi document processor
            result = self.context.process_document(
                file_path=file.name,
                processing_mode=processing_mode,
                use_gpu=use_gpu,
                enable_ocr=enable_ocr,
                enable_table_structure=enable_table_structure,
                enable_cleaning=enable_cleaning,
                aggressive_clean=aggressive_clean,
                enable_chunking=enable_chunking,
                chunking_strategy=chunking_strategy,
                chunk_size=chunk_size,
                chunk_overlap=chunk_overlap,
                task_type=task_type,
                *generation_params
            )
            
            # X·ª≠ l√Ω l·ªói
            if "error" in result:
                return f"‚ùå {result['error']}", "", ""
            
            # Format outputs
            summary = self._create_document_summary(result)
            detailed_json = json.dumps(result, indent=2, ensure_ascii=False)
            chunks_preview = self._create_chunks_preview(result.get("sample_chunks", []))
            
            return summary, detailed_json, chunks_preview
            
        except Exception as e:
            error_msg = f"‚ùå Document processing failed: {str(e)}"
            return error_msg, "", ""
    
    def _create_document_summary(self, result: Dict[str, Any]) -> str:
        """
        T·∫°o summary cho document processing results
        
        Args:
            result: K·∫øt qu·∫£ document processing
            
        Returns:
            Formatted summary markdown
        """
        from pathlib import Path
        
        # Basic info
        file_name = Path(result['file_path']).name
        processing_time = result['processing_time']
        original_length = result['original_content_length']
        cleaned_length = result['cleaned_content_length']
        chunks_created = result['chunks_created']
        
        # Chunking stats
        chunking_stats = result['metadata']['chunking_stats']
        avg_chunk_size = chunking_stats['avg_chunk_size']
        strategy_used = chunking_stats['strategy_used']
        
        # Generation info
        gen_info = result.get('generation_info', {})
        gen_params = gen_info.get('parameters_used', {})
        total_inference_time = gen_info.get('total_inference_time', 0)
        
        summary = f"""
üìÑ **File:** {file_name}
‚è±Ô∏è **Processing Time:** {processing_time:.2f}s
üìä **Content:** {original_length:,} ‚Üí {cleaned_length:,} chars
üìù **Chunks Created:** {chunks_created}
üìà **Avg Chunk Size:** {avg_chunk_size} chars
üéØ **Strategy:** {strategy_used}

**üéõÔ∏è Generation Settings:**
- Temperature: {gen_params.get('temperature', 'N/A')}
- Max Tokens: {gen_params.get('max_new_tokens', 'N/A')}
- Top-p: {gen_params.get('top_p', 'N/A')}
- Inference Time: {total_inference_time:.2f}s
        """.strip()
        
        return summary
    
    def _create_chunks_preview(self, sample_chunks: list) -> str:
        """
        T·∫°o preview cho sample chunks
        
        Args:
            sample_chunks: List c√°c sample chunks
            
        Returns:
            Formatted chunks preview
        """
        if not sample_chunks:
            return "No chunks available for preview."
        
        preview_parts = []
        for chunk in sample_chunks:
            chunk_id = chunk['chunk_id']
            content = chunk['content']
            size = chunk['size']
            tokens = chunk['tokens']
            
            preview_parts.append(
                f"**Chunk {chunk_id} ({size} chars, {tokens} tokens):**\n{content}"
            )
        
        return "\n\n".join(preview_parts)
    
    # ============================================================================
    # CHUNK EXTRACTION HANDLERS
    # ============================================================================
    
    def process_chunk_extraction(self, chunks_data: str, task: str, entity_types: str,
                                relation_types: str, event_types: str, argument_types: str,
                                mode: str, *generation_params) -> Tuple[str, str]:
        """
        X·ª≠ l√Ω extraction t·ª´ document chunks
        
        Args:
            chunks_data: JSON string ch·ª©a chunks data
            task: Extraction task
            entity_types, etc.: Schema parameters
            mode: Extraction mode
            *generation_params: Generation parameters
            
        Returns:
            Tuple[summary_markdown, detailed_json]
        """
        # Ki·ªÉm tra chunks data
        if not chunks_data or not chunks_data.strip():
            return "‚ùå No chunks data available", ""
        
        try:
            # G·ªçi chunk extraction
            result = self.context.extract_from_chunks(
                chunks_data=chunks_data,
                task=task,
                entity_types=entity_types,
                relation_types=relation_types,
                event_types=event_types,
                argument_types=argument_types,
                mode=mode,
                *generation_params
            )
            
            # X·ª≠ l√Ω l·ªói
            if "error" in result:
                return f"‚ùå {result['error']}", ""
            
            # Format outputs
            summary = self._create_chunk_extraction_summary(result)
            detailed_json = json.dumps(result, indent=2, ensure_ascii=False)
            
            return summary, detailed_json
            
        except Exception as e:
            error_msg = f"‚ùå Chunk extraction failed: {str(e)}"
            return error_msg, ""
    
    def _create_chunk_extraction_summary(self, result: Dict[str, Any]) -> str:
        """
        T·∫°o summary cho chunk extraction results
        
        Args:
            result: K·∫øt qu·∫£ chunk extraction
            
        Returns:
            Formatted summary markdown
        """
        # Basic stats
        total_chunks = result['total_chunks_processed']
        processing_time = result['processing_time']
        
        # Aggregated results
        aggregated = result['aggregated_results']
        total_entities = len(aggregated['entities'])
        total_relations = len(aggregated['relations'])
        total_events = len(aggregated['events'])
        
        # Performance metrics
        perf = result['performance_metrics']
        avg_time_per_chunk = perf['avg_time_per_chunk']
        tokens_generated = perf['tokens_generated']
        tokens_per_second = perf['tokens_per_second']
        memory_usage = perf['memory_usage']
        
        # Generation parameters
        gen_params = result['generation_parameters']
        
        summary = f"""
üìä **Chunks Processed:** {total_chunks}
‚è±Ô∏è **Total Time:** {processing_time:.2f}s
üè∑Ô∏è **Entities Found:** {total_entities}
üîó **Relations Found:** {total_relations}
üìÖ **Events Found:** {total_events}

**üöÄ Performance:**
- Avg Time/Chunk: {avg_time_per_chunk:.3f}s
- Tokens Generated: {tokens_generated:,}
- Speed: {tokens_per_second:.1f} tokens/sec
- Memory: {memory_usage}

**üéõÔ∏è Generation Used:**
- Temperature: {gen_params['temperature']}
- Max Tokens: {gen_params['max_new_tokens']}
- Top-p: {gen_params['top_p']}
- Beams: {gen_params['num_beams']}
        """.strip()
        
        return summary
    
    # ============================================================================
    # GENERATION PRESET HANDLERS
    # ============================================================================
    
    def apply_generation_preset(self, preset_name: str, *current_values) -> tuple:
        """
        √Åp d·ª•ng generation parameter preset
        
        Args:
            preset_name: T√™n preset (conservative, balanced, creative, precise)
            *current_values: Current values c·ªßa generation parameters
            
        Returns:
            Tuple c√°c values m·ªõi sau khi √°p d·ª•ng preset
        """
        return GenerationPresets.apply_preset(preset_name, current_values)


class TabEventHandlers:
    """
    Helper class ƒë·ªÉ setup event handlers cho t·ª´ng tab m·ªôt c√°ch c√≥ t·ªï ch·ª©c
    """
    
    def __init__(self, handlers: EventHandlers):
        self.handlers = handlers
    
    def setup_text_extraction_tab(self, components: Dict[str, Any]):
        """
        Setup event handlers cho Text Extraction tab
        
        Args:
            components: Dictionary ch·ª©a c√°c Gradio components c·ªßa tab
        """
        inputs = components['inputs']
        outputs = components['outputs']
        
        # Sample text loading
        inputs['sample_dropdown'].change(
            fn=self.handlers.load_sample_text,
            inputs=[inputs['sample_dropdown']],
            outputs=[inputs['text_input']]
        )
        
        # Generation preset buttons
        self._setup_preset_buttons(inputs['gen_controls'])
        
        # Main extraction button
        inputs['extract_btn'].click(
            fn=self.handlers.process_text_extraction,
            inputs=[
                inputs['text_input'],
                inputs['task_dropdown'],
                *inputs['schema_inputs'],  # entity_types, relation_types, etc.
                inputs['mode_dropdown'],
                *inputs['gen_controls'][:9]  # Generation parameters (exclude buttons)
            ],
            outputs=[
                outputs['summary_output'],
                outputs['json_output']
            ]
        )
    
    def setup_document_processing_tab(self, components: Dict[str, Any]):
        """
        Setup event handlers cho Document Processing tab
        
        Args:
            components: Dictionary ch·ª©a c√°c Gradio components c·ªßa tab
        """
        inputs = components['inputs']
        outputs = components['outputs']
        
        # Generation preset buttons
        self._setup_preset_buttons(inputs['gen_controls'])
        
        # Document processing button
        inputs['process_btn'].click(
            fn=self.handlers.process_document_upload,
            inputs=[
                inputs['file_upload'],
                # processing options
                inputs['processing_options']['processing_mode'],
                inputs['processing_options']['use_gpu'],
                inputs['processing_options']['enable_ocr'],
                inputs['processing_options']['enable_table_structure'],
                # cleaning options
                inputs['cleaning_options']['enable_cleaning'],
                inputs['cleaning_options']['aggressive_clean'],
                # chunking options
                inputs['chunking_options']['enable_chunking'],
                inputs['chunking_options']['chunking_strategy'],
                inputs['chunking_options']['chunk_size'],
                inputs['chunking_options']['chunk_overlap'],
                inputs['chunking_options']['task_type'],
                # generation parameters
                *inputs['gen_controls'][:9]
            ],
            outputs=[
                outputs['summary_output'],
                outputs['json_output'],
                outputs['chunks_preview']
            ]
        )
    
    def setup_chunk_extraction_tab(self, components: Dict[str, Any]):
        """
        Setup event handlers cho Chunk Extraction tab
        
        Args:
            components: Dictionary ch·ª©a c√°c Gradio components c·ªßa tab
        """
        inputs = components['inputs']
        outputs = components['outputs']
        
        # Generation preset buttons
        self._setup_preset_buttons(inputs['gen_controls'])
        
        # Chunk extraction button
        inputs['extract_btn'].click(
            fn=self.handlers.process_chunk_extraction,
            inputs=[
                inputs['chunks_data_storage'],
                inputs['task_mode_controls']['task_dropdown'],
                inputs['schema_inputs']['entity_types'],
                inputs['schema_inputs']['relation_types'],
                inputs['schema_inputs']['event_types'],
                inputs['schema_inputs']['argument_types'],
                inputs['task_mode_controls']['mode_dropdown'],
                *inputs['gen_controls'][:9]  # Generation parameters
            ],
            outputs=[
                outputs['summary_output'],
                outputs['results_output']
            ]
        )
    
    def _setup_preset_buttons(self, gen_controls: tuple):
        """
        Setup generation preset buttons cho m·ªôt tab
        
        Args:
            gen_controls: Tuple ch·ª©a generation controls include preset buttons
        """
        # Conservative preset
        gen_controls[9].click(
            fn=lambda *args: self.handlers.apply_generation_preset("conservative", *args),
            inputs=list(gen_controls[:9]),
            outputs=list(gen_controls[:9])
        )
        
        # Balanced preset
        gen_controls[10].click(
            fn=lambda *args: self.handlers.apply_generation_preset("balanced", *args),
            inputs=list(gen_controls[:9]),
            outputs=list(gen_controls[:9])
        )
        
        # Creative preset
        gen_controls[11].click(
            fn=lambda *args: self.handlers.apply_generation_preset("creative", *args),
            inputs=list(gen_controls[:9]),
            outputs=list(gen_controls[:9])
        )
        
        # Precise preset
        gen_controls[12].click(
            fn=lambda *args: self.handlers.apply_generation_preset("precise", *args),
            inputs=list(gen_controls[:9]),
            outputs=list(gen_controls[:9])
        )


def setup_event_handlers(demo, components: Dict[str, Any], handlers: EventHandlers):
    """
    Main function ƒë·ªÉ setup t·∫•t c·∫£ event handlers
    
    Args:
        demo: Gradio Blocks object
        components: Dictionary ch·ª©a components c·ªßa t·∫•t c·∫£ tabs
        handlers: EventHandlers instance
    """
    # Create tab handlers helper
    tab_handlers = TabEventHandlers(handlers)
    
    # Setup handlers cho t·ª´ng tab
    tab_handlers.setup_text_extraction_tab(components['text_extraction'])
    tab_handlers.setup_document_processing_tab(components['document_processing'])
    tab_handlers.setup_chunk_extraction_tab(components['chunk_extraction'])
    
    print("‚úÖ All event handlers setup successfully!")